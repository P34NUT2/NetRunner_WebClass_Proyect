#########################################
# Postgresito como DB
#########################################
services:
  postgres:
    image: postgres:15
    container_name: postgres_db
    restart: always
    environment:
      POSTGRES_USER: webdev
      POSTGRES_PASSWORD: InsecurePasswd
      POSTGRES_DB: netrunner
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - netrunner_network

#########################################
# Terminal grÃ¡fica para PostgreSQL
#########################################
  ##se que este no lo ocupa usted pero me sirve para meter datos 
  ##y manejarlos desde ahi igual se lo dejo por si quiere usar este docker
  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@dev.com
      PGADMIN_DEFAULT_PASSWORD: InsecurePasswd
    ports:
      - "8080:80"
    depends_on:
      - postgres
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    networks:
      - netrunner_network

########################################################
# Ollama para IA (llama3.2)
########################################################
  ollama:
    image: ollama/ollama:latest
    container_name: netrunner_ollama
    restart: always
    ports:
      - "11434:11434"
    volumes:
      # Guardar modelos descargados (2-10GB)
      - ollama_data:/root/.ollama
      # Montar el Modelfile para crear modelo personalizado
      - ./netrunner-model:/netrunner-model:ro
    networks:
      - netrunner_network
    environment:
      - OLLAMA_HOST=0.0.0.0
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3

########################################################
# Script para descargar llama3.2 automÃ¡ticamente
# NOTA: Solo descarga si el modelo NO existe (verifica primero)
# El modelo se guarda en ollama_data (persistente entre reinicios)
########################################################
  ollama-pull:
    image: docker:cli
    container_name: ollama_model_puller
    depends_on:
      ollama:
        condition: service_healthy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    entrypoint: /bin/sh
    command: >
      -c "
      echo 'ðŸš€ Verificando modelo llama3.2...';
      docker exec netrunner_ollama ollama pull llama3.2;
      echo 'âœ… Modelo listo para usar!';
      "
    restart: "no"

#########################################
# Redes
#########################################
networks:
  netrunner_network:
    driver: bridge

#########################################
# VolÃºmenes
#########################################
volumes:
  postgres_data:
  pgadmin_data:
  ollama_data:
